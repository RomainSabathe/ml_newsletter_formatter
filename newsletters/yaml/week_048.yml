articles:
  - category: ml
    description: 'If you are like me and know nothing about causal inference then
      this blog post will be an interesting read! We learn how 3 seemingly same Gaussian
      distributions can actually reveal having fundamental differences. How? By the
      way they are generated. If an external agent was to apply a same intervention
      on the generation process then the three resulting distributions would be a
      lot different! This is a good reminder that, as the last figure of the blog
      shows, data distribution does not necessarily explains <i>everything</i> about
      the data. What I''m saying doesn''t make any sense? Then you should read the
      post! ;-)'
    lab: 'inFERENCe (Ferenc Huszár)'
    title: 'Causal Inference 2: Illustrating Interventions via a Toy Example'
    type: blog
    url: https://www.inference.vc/causal-inference-2-illustrating-interventions-in-a-toy-example/
  - category: cv
    description: 'Just over a month ago, a team at NVIDIA submitted a paper showing
      <a href=https://arxiv.org/abs/1812.04948>new state-of-the-art results</a> on
      image generation using GANs. Among the novelties brought by the paper: a mapping
      of the usual latent space from where latent codes z are sampled; the use of
      <a href=https://arxiv.org/abs/1703.06868>adaptative instance normalization</a>
      at different stages of the generator and some noise added to the feature maps
      during the generation process. If you are not interested in all the specifics
      details of the paper, this blog post is perfect for you to get the gist of it.'
    lab: 'Cody Marie Wild'
    recommended: true
    title: 'Generating, With Style: The Mechanics Behind NVIDIA’s Highly Realistic
      GAN Images'
    type: blog
    url: https://medium.com/@cody.marie.wild/generating-with-style-the-mechanics-behind-nvidias-highly-realistic-gan-images-b6937237e3c6?sk=556a85aa3ff3bc05bb439c983564dfe9
  - category: ml
    description: 'A new post on Gaussian Processes! This one is slightly different
      from the posts we had a couple weeks ago  in the sense that the author focuses
      more on similarities that Gaussian Processes have with k-nearest neighbours
      and linear regression. For a better introduction to GPs, see the posts we referred
      in a previous newsletter (<a href=https://peterroelants.github.io/posts/gaussian-process-tutorial/>here</a>
      and <a href=https://www.jgoertler.com/visual-exploration-gaussian-processes/>here</a>).'
    lab: 'Aaron Schumacher'
    title: 'Gaussian Processes are Not So Fancy'
    type: blog
    url: https://planspace.org/20181226-gaussian_processes_are_not_so_fancy/
  - category: dl
    description:
    lab: 'Universidade Federal do Espírito Santo Vitória, Brasil'
    quote: 'We survey research on self-driving cars published in the literature focusing
      on autonomous cars developed since the DARPA challenges, [...] In this survey,
      we present the typical architecture of the autonomy system of self-driving cars.
      We also review research on relevant methods for perception and decision making.
      Furthermore, we present a detailed description of the architecture of the autonomy
      system of the UFES''s car, IARA. Finally, we list prominent autonomous research
      cars developed by technology companies and reported in the media.'
    title: "[arXiv] Self-Driving Cars: A Survey"
    type: paper
    url: https://arxiv.org/abs/1901.04407
  - category: rl
    description: 'StarCraft II is close to be solved it appears! Yesterday, DeepMind
      released the footage of 10 games played by their newest agent called AlphaStar
      against two professional players (MaNa and TLO). AlphaStar won every single
      game! DeepMind shares some of the ideas that were used to build AlphaStar in
      this post. Obviously, state-of-the-art reinforcement learning is necessary  (with
      methods such as experience-replay, self-imitation learning, policy distillation).
      But more interestingly, much of the progress of the agent has been obtained
      in the last two months by organising a virtual tournament called the AlphaStar
      League. In the League, several versions of AlphaStar were competing against
      each other and each agent had a different learning objective. This consistently
      increased the Nash distribution of the agents, until the best agent was good
      enough to beat professional players.'
    lab: DeepMind
    recommended: true
    title: 'AlphaStar: Mastering the Real-Time Strategy Game StarCraft II'
    type: blog
    url: https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/
  - category: theory
    description:
    lab: 'Department of Informatics, University of Oslo, Norway'
    quote: 'Gaining a better understanding of how and what machine learning systems
      learn is important to increase confidence in their decisions and catalyze further
      research. In this paper, we analyze the predictions made by a specific type
      of recurrent neural network, mixture density RNNs (MD-RNNs). These networks
      learn to model predictions as a combination of multiple Gaussian distributions,
      making them particularly interesting for problems where a sequence of inputs
      may lead to several distinct future possibilities.[...]'
    title: "[arXiv] How do Mixture Density RNNs Predict the Future?"
    type: paper
    url: https://arxiv.org/abs/1901.07859
  - category: engineering
    description: 'Here''s a repo that started in September 2018 but that I was not
      aware of. I am sure it will prove to be extremely useful as it provides a common
      interface to access some standard datasets like MNIST, CIFAR, COCO, ImageNet,
      SVHN, CelebA and even non-image datasets like IMDB-Reviews. To use the dataset,
      it''s super simple: <code>datasets = tfds.load(name=''mnist'')</code>.'
    lab: Tensorflow
    title: 'tensorflow/datasets: A collection of datasets ready to use with TensorFlow'
    type: blog
    url: https://trello-attachments.s3.amazonaws.com/5bf506f9456de85b3a3d0024/5c481fff860a545120e9b248/a3baff8cc1aacdd1cbf31199c00eb732/15658638.png
  - category: theory
    description:
    lab: 'Montreal   Institute   for   Learning   Algorithms, Universite de Montreal'
    quote: 'It has been noted in existing literature that over-parameterization in
      ReLU networks generally leads to better performance. While there could be several
      reasons for this, we investigate desirable network properties at initialization
      which may be enjoyed by ReLU networks. [...] In the case of deep ReLU networks
      with weight vectors normalized by their norm, we derive an initialization required
      to tap the aforementioned benefits from over-parameterization without which
      network fails to learn for large depth.'
    title: "[arXiv] The Benefits of Over-parameterization at Initialization in Deep\
      \ ReLU Networks"
    type: paper
    url: https://arxiv.org/abs/1901.03611
  - category: rl
    description: 'This is a concise tutorial on how to implement an Advantage Actor-Critic
      agent with Tensorflow 2.0, taking advantage of the Keras API. It is well thought
      as we build the model piece-by-piece in meaningful steps. The author also offers
      a reminder of what an advantage actor-critic is and how it differs from value-based
      methods.'
    lab: 'Roman Ring'
    title: 'Deep Reinforcement Learning with TensorFlow 2.0'
    type: blog
    url: http://inoryy.com/post/tensorflow2-deep-reinforcement-learning/
intro_text: ""
outro_text: ""
