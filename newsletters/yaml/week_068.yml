articles:
  - category: dl
    description:
    img: https://i.ibb.co/XZ054nt/Selection-238.png
    lab: 'Facebook AI Research'
    quote: 'Data-augmentation is key to the training of neural networks for image
      classification. This paper first shows that existing augmentations induce a
      significant discrepancy between the typical size of the objects seen by the
      classifier at train and test time. We experimentally validate that, for a target
      test resolution, using a lower train resolution offers better classification
      at test time. We then propose a simple yet effective and efficient strategy
      to optimize the classifier performance when the train and test resolutions differ.
      It involves only a computationally cheap fine-tuning of the network at the test
      resolution. This enables training strong classifiers using small training images.
      For instance, we obtain 77.1% top-1 accuracy on ImageNet with a ResNet-50 trained
      on 128x128 images, and 79.8% with one trained on 224x224 image. In addition,
      if we use extra training data we get 82.5% with the ResNet-50 train with 224x224
      images. Conversely, when training a ResNeXt-101 32x48d pre-trained in weakly-supervised
      fashion on 940 million public images at resolution 224x224 and further optimizing
      for test resolution 320x320, we obtain a test top-1 accuracy of 86.4% (top-5:
      98.0%) (single-crop). To the best of our knowledge this is the highest ImageNet
      single-crop, top-1 and top-5 accuracy to date.'
    title: "[arXiv] Fixing the train-test resolution discrepancy"
    type: paper
    url: https://arxiv.org/abs/1906.06423
  - category: dl
    description:
    lab: 'Universite de Montreal, McGill University, University of Texas - El Paso,
      Polytechnique Montreal, Mila, Element AI'
    quote: 'Batch normalization has been widely used to improve optimization in deep
      neural networks. While the uncertainty in batch statistics can act as a regularizer,
      using these dataset statistics specific to the training set impairs generalization
      in certain tasks. Recently, alternative methods for normalizing feature activations
      in neural networks have been proposed. Among them, group normalization has been
      shown to yield similar, in some domains even superior performance to batch normalization.
      All these methods utilize a learned affine transformation after the normalization
      operation to increase representational power. Methods used in conditional computation
      define the parameters of these transformations as learnable functions of conditioning
      information. In this work, we study whether and where the conditional formulation
      of group normalization can improve generalization compared to conditional batch
      normalization. We evaluate performances on the tasks of visual question answering,
      few-shot learning, and conditional image generation.'
    title: "[arXiv] An Empirical Study of Batch Normalization and Group Normalization\
      \ in Conditional Computation"
    type: paper
    url: https://arxiv.org/abs/1908.00061v1
  - category: ml
    description:
    img: https://camo.githubusercontent.com/c16b1b4f3fbc7e64f219ea1f51712b748769180f/68747470733a2f2f646f63732e676f6f676c652e636f6d2f64726177696e67732f642f652f32504143582d3176536c383054344d6e5752735058334b766c42326b6e367a56644864556c65475f77327a42694c533752784c47414878695359546e77334c5a7458685f5f594d76364b63494f594f766b53743950422f7075623f773d38343126683d333530
    lab: 'Creme ML'
    quote: 'creme is a library for online machine learning, also known as incremental
      learning. Online learning is a machine learning regime where a model learns
      one observation at a time. This is in contrast to batch learning where all the
      data is processed in one go. Incremental learning is desirable when the data
      is too big to fit in memory, or simply when you want to handle data in a streaming
      fashion. In addition to many online machine learning algorithms, creme provides
      utilities for extracting features from a stream of data. The API is heavily
      inspired from that of scikit-learn, meaning that users who are familiar with
      it should feel comfortable.'
    title: 'Creme: Online machine learning in Python'
    type: github
    url: https://github.com/creme-ml/creme
  - category: dl
    description:
    img: https://github.com/taki0112/UGATIT/raw/master/assets/teaser.png
    lab: 'Junho Kim (NCSoft AI Research)'
    quote: 'We propose a novel method for unsupervised image-to-image translation,
      which incorporates a new attention module and a new learnable normalization
      function in an end-to-end manner. The attention module guides our model to focus
      on more important regions distinguishing between source and target domains based
      on the attention map obtained by the auxiliary classifier. Unlike previous attention-based
      methods which cannot handle the geometric changes between domains, our model
      can translate both images requiring holistic changes and images requiring large
      shape changes. Moreover, our new AdaLIN (Adaptive Layer-Instance Normalization)
      function helps our attention-guided model to flexibly control the amount of
      change in shape and texture by learned parameters depending on datasets. Experimental
      results show the superiority of the proposed method compared to the existing
      state-of-the-art models with a fixed network architecture and hyper-parameters.'
    title: 'U-GAT-IT â€” Official TensorFlow Implementation'
    type: github
    url: https://github.com/taki0112/UGATIT
  - category: theory
    description:
    lab: 'University of California, Los Angeles'
    quote: 'Whatever information a Deep Neural Network has gleaned from past data
      is encoded in its weights. How this information affects the response of the
      network to future data is largely an open question. In fact, even how to define
      and measure information in a network is still not settled. We introduce the
      notion of Information in the Weights as the optimal trade-off between accuracy
      of the network and complexity of the weights, relative to a prior. Depending
      on the prior, the definition reduces to known information measures such as Shannon
      Mutual Information and Fisher Information, but affords added flexibility that
      enables us to relate it to generalization, via the PAC-Bayes bound, and to invariance.
      This relation hinges not only on the architecture of the model, but surprisingly
      on how it is trained. We then introduce a notion of effective information in
      the activations, which are deterministic functions of future inputs, resolving
      inconsistencies in prior work. We relate this to the Information in the Weights,
      and use this result to show that models of low complexity not only generalize
      better, but are bound to learn invariant representations of future inputs.'
    title: "[arXiv] Where is the Information in a Deep Neural Network?"
    type: paper
    url: https://arxiv.org/abs/1905.12213
  - category: engineering
    description: 'This project is presented as the <i>''PyTorch Keras for ML researchers''</i>.
      It invites the user to structure the codebase in a specific manner with a Model
      class that integrates a train_step method, val_step method, loss method and
      others. In return, pytorch-lightning relieves the user from having to write
      some usual boilerplate code like model saving/loading, mixed-precision training
      and Tensorboard support. Another popular alternative is the <a href=https://github.com/pytorch/ignite>Ignite
      package</a>.'
    img: https://github.com/williamFalcon/pytorch-lightning/raw/master/docs/source/_static/overview_flat.jpg
    lab: 'William Falcon'
    title: 'pytorch-lightning: Rapid research framework for PyTorch'
    type: github
    url: https://github.com/williamFalcon/pytorch-lightning
  - category: gan
    description: 'A few months ago, the paper <a href=https://arxiv.org/abs/1905.02175>Adversarial
      Examples Are Not Bugs, They Are Features</a> sparked interest. In short, authors
      indicate in this work that adversarial attacks are not an issue that has to
      do with <i>models</i> necessarily, but rather with patterns in the image dataset
      that are imperceptible to us humans. Since these patterns are valid discriminative
      features, the models tend to rely on them to perform the classification. Yet
      those features are altered when adversarially attacked. They therefore loose
      their discriminative power and the model is bound to misclassify. I believe
      this unusual way of thinking about adversarial attacks explain why the paper
      has received this much interest. <br /> Distill decided to put this interest
      to good use and gathered 6 detailed comments submitted by external research
      labs who shed lights on the problem. Think about this as an highly educated
      follow-up discussion during a reading group. There are those who <a href=https://distill.pub/2019/advex-bugs-discussion/response-3/>are
      trying to visualise what these imperceptible patterns might look like</a> and
      others who <a href=https://distill.pub/2019/advex-bugs-discussion/response-5/>remind
      that adversarial attacks are not entirely due to imperceptible features</a>.
      That is a wonderful idea from Distill to deepens one''s understanding of the
      original paper.'
    img: https://trello-attachments.s3.amazonaws.com/5d4a6814f9905032cee7ad4d/840x400/00a4c60ce47e8779f58d318b876486e9/thumbnail.jpg
    lab: Distill
    recommended: true
    title: 'A Discussion of ''Adversarial Examples Are Not Bugs, They Are Features'''
    type: paper
    url: https://distill.pub/2019/advex-bugs-discussion/
intro_text: ""
outro_text: ""
