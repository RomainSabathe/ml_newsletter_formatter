intro_text:

outro_text:

articles:
    - title: "Google Images Downloader"
      recommended: false
      type: "github"
      category: "Everything Else"
      lab: ""
      url: "https://github.com/hardikvasa/google-images-download"
      description: "Python Script for searching and downloading hundreds of Google images to the local hard disk. Seems handy to create small datasets."
      quote:
          ""

    - title: "Making the distinction between Maximum Likelihood, MAP and Bayesian Parameter Estimation"
      recommended: false
      type: "medium"
      category: "General Machine Learning"
      lab: ""
      url: "https://medium.com/@amatsukawa/maximum-likelihood-maximum-a-priori-and-bayesian-parameter-estimation-d99a23a0519f"
      description: "4 mins read. Straight to the point."
      quote:
          ""

    - title: "Lessons Learned Reproducting a Deep Reinforcement Learning Paper"
      recommended: true
      category: "drl"
      type: "blog"
      lab: "Amid Fish"
      url: "http://amid.fish/reproducing-deep-rl#fnref:norm2"
      description: "This person wanted to implement the famous Deep Reinforcement Learning From Human Preferences as a side project. He estimated it would take him 3 months, most of it being implementation. It actually took 8 months, most of it was tweaking and debugging. This post has been highly praised online, especially among the DRL community. The author shares hindsights and advises (regarding DRL, machine learning in general, Python, Tensorflow...). I particularly liked his statement on the sense of <i>confusion</i>."
      quote: "Develop the habit of following through on confusion. There are some sources of discomfort that it can be better to ignore in the moment (e.g. code smell while prototyping), but confusion isnâ€™t one of them. It seems important to really commit yourself to always investigate whenever you notice confusion."


    - title: "Viz Palette"
      recommended: false
      category: "vis"
      type: ""
      lab: ""
      url: "http://projects.susielu.com/viz-palette"
      description: "A neat tool to build a nice-looking, color bling-friendly color palette!"
      quote: ""

    - title: "A collection of NLP datasets"
      recommended: false
      category: "NLP"
      type: "github"
      lab: ""
      url: "https://github.com/niderhoff/nlp-datasets"
      description: ""
      quote: ""

    - title: "Neural Autoregressive Flows"
      recommended: false
      category: "ml"
      type: "paper"
      lab: "MILA, University of Montreal, Element AI"
      url: "https://arxiv.org/abs/1804.00779"
      description: ""
      quote: "We demonstrate that the proposed neural autoregressive flows (NAF) are universal approximators for continuous probability distributions, and their greater expressivity allows them to better capture multimodal target distributions"

    - title: "Associative Compression Networks"
      recommended: false
      category: "ml"
      type: "paper"
      lab: "DeepMind (Alex Graves et al.)"
      url: "https://arxiv.org/abs/1804.02476"
      description: ""
      quote: "This paper introduces Associative Compression Networks (ACNs), a new framework for variational autoencoding with neural networks. The system differs from existing variational autoencoders in that the prior distribution used to model each code is conditioned on a similar code from the dataset. [...] [Experiments] also demonstrate that ACNs learn high-level features such as object class, writing style, pose and facial expression, which can be used to cluster and classify the data, as well as to generate diverse and convincing samples."

    - title: "Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations"
      recommended: false
      category: "dl"
      type: "paper"
      lab: "MILA"
      url: "https://arxiv.org/abs/1804.02485"
      description: ""
      quote: "We propose Fortified Networks, a simple transformation of existing networks, which fortifies the hidden layers in a deep network by identifying when the hidden states are off of the data manifold, and maps these hidden states back to parts of the data manifold where the network performs well. Our principal contribution is to show that fortifying these hidden states improves the robustness of deep networks and our experiments demonstrate improved robustness to standard adversarial attacks in both black-box and white-box threat models [...]"

    - title: "Play music embeddings online"
      recommended: false
      category: ""
      type: ""
      lab: ""
      url: "https://codepen.io/teropa/full/rdoPbG/"
      description: "This web app uses (as far as I understood) a Magenta backend to compose music on the fly. You can choose which part of the latent space to explore and set the associated chord you want. Kind of dreamy. :-)"
      quote: ""

    - title: "Diving deeper into Reinforcement Learning with Q-Learning"
      recommended: false
      category: "drl"
      type: "medium"
      lab: "8 mins read - Thomas Simonini"
      url: "https://medium.freecodecamp.org/diving-deeper-into-reinforcement-learning-with-q-learning-c18d0db58efe"
      description: "The second post of a series on introducing deep reinforcement learning (yes, another one). You can find the first post <a href=https://medium.freecodecamp.org/an-introduction-to-reinforcement-learning-4339519de419>here</a>. I found the specificity of this series is to emphasize intuitive explanations using diagrams and explicit examples. This specific post deals with Q-Learning which is a well-known algorithm pre deep learning era."
      quote: ""

    - title: "Learning Rate Finder for Keras"
      recommended: false
      category: "optim"
      type: "github"
      lab: ""
      url: "https://github.com/nathanhubens/Learning-Rate"
      description: "A few callbaks that use Keras' backend to implement SGD with restart and cyclical learning rate. There's also an 'optimal learning rate finder' which seemed a bit dubious to me..."
      quote: ""

    - title: "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization"
      recommended: false
      category: "inter"
      type: "paper + github"
      lab: "Virginia Tech, Georgia Institute of Technology"
      url: "https://arxiv.org/abs/1610.02391"
      description: "This paper proposes a method to interpret decisions from a CNN architecture. This has been attempted in the past; yet the novelty of this paper is that their method can be used in a variety of applications and architectures (classification, reinforcement learning, captioning, visual question answering,...). A Pytorch implementation is available <a href=https://github.com/meliketoy/gradcam.pytorch>here</a>."
      quote: "We propose a technique for producing 'visual explanations' for decisions from a large class of CNN-based models, making them more transparent. Our approach - Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept, flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept."

    - title: "Differentiable Plasticity: A New Method for Learning to Learn"
      recommended: true
      category: "optim"
      type: "blog"
      lab: "Uber"
      url: "https://eng.uber.com/differentiable-plasticity/"
      description: "The kind of idea that gets me excited. The goal is simple to formulate: they are trying to model the plasticity of the brain and to incorporate it in the standard deep learning framework with gradient descent. Their suggested solution is to extend the weights so that they have two components. The first one changes over time depending on the inputs (that's the plasticity part) while the second one is fixed over time and can be seen as a traditional weight. During training, a parameter is learned to determine which of the first or second component should be predominant. Ideally, this should produce a network which has at the same time fixed connections (ideal for learned tasks) and plastic connections (suitable for retraining and few-shot learning)."
      quote: "While evolving such plastic neural networks is a longstanding area of research in evolutionary computation, to our knowledge the work introduced here is the first to show it is possible to optimize plasticity itself through gradient descent."

    - title: "Towards a Virtual Stuntman"
      recommended: false
      category: "drl"
      type: "blog + paper"
      lab: "Berkely Artificial Intelligence Research"
      url: "http://bair.berkeley.edu/blog/2018/04/10/virtual-stuntman/"
      description: "This paper presents a reward functions and a few tricks to make an agent learn realistic movements from a single training sample. The reward function is (as they say) quite simple: it consists in minimizing the L2 distance between the current pose and the target pose and to do this over time. Among the tricks they used, they suggested to initialise the simulation at mid-course of the action. For instance, if you want to teach a backflip, you can initialise the simulation when the agent is in the air and needs to fall on the floor. This forces the exploration  of rewards that otherwise would never had been discovered if the agent had started on the floor. Also, they suggest that early termination (i.e. the action of stopping the simulation when it obviously failed) plays a determinant role. For example, back to the idea of backflip, if the agent fails to jump and land and the floor, we should terminate the simulation. Otherwise, the agent will try to do the movements of a backflip on the ground and will likely get some reward out of it. Next time, it'll be incentivized to do the movement directly on the floor."
      quote: ""

    - title: "TensorFlow Probability"
      recommended: false
      category: "ml"
      type: "medium"
      lab: "Google"
      url: "https://medium.com/tensorflow/introducing-tensorflow-probability-dca4c304e245"
      description: "Tensorflow keeps growing... And now I can't even understand the examples (also due my lack of knowledge on probabilistic models). :|"
      quote: "We announce TensorFlow Probability: a probabilistic programming toolbox for machine learning researchers and practitioners to quickly and reliably build sophisticated models that leverage state-of-the-art hardware."

    - title: "Looking to Listen: Audio-Visual Speech Recognition"
      recommended: false
      category: "dl"
      type: "blog"
      lab: "Google Research"
      url: "https://research.googleblog.com/2018/04/looking-to-listen-audio-visual-speech.html"
      description: "Researchers solve the cocktail party problem using audio information,... but also visual information. They gathered 2,000 hours of Youtube videos to train their model. Faces are detected first to extract video features. The audio features consist of a Fourier transform. Audio-Visual features are concatenated and passed to recurrent layers. The ouput is an audio mask that we can apply to the original audio stream. We'll get as many masks as there are of speakers (and depending on the training procedure). Applying the mask isolates the audio from one speaker to the other. The examples shown are super convincing!"
      quote: ""

    - title: "12 Atomic Experiments in Deep Learning"
      recommended: true
      category: "dl"
      type: "blog"
      lab: "Zou Group @Stanford"
      url: "https://abidlabs.github.io/Atomic-Experiments/"
      description: "A collection of 12 small but worthy experiments that can be ran on CPU for a couple minutes each. It goes from 'are all activation function performing equally?' to 'to what extent does adding data improve performance?' and so on. Take with a pinch of salt though; all the networks used are still relatively small (about 4 layers) and fully connected."
      quote: ""

    - title: "Compute-Features"
      recommended: false
      category: "cv"
      type: "github"
      lab: ""
      url: "https://github.com/cameronfabbri/Compute-Features"
      description: "Nice and handy. A small Python script to extract features from a given image. It supports many architectures (that you have to download separately): Inception V1-4, Inception-ResNet, ResNet V1-2, VGG 16 and 19."
      quote: ""

    - title: "EPIC-Kitchens"
      recommended: false
      category: ""
      type: ""
      lab: "University of Bristol, University of Toronto, Universita degli Studi di Catania"
      url: "https://epic-kitchens.github.io/2018"
      description: "55 hours of full-hd 60fps recordings of... first-person views of activities performed in a kitchen: cooking, slicing, washing the dishes... The actions are anotated and they also provide bounding boxes for objects. Lot of work behind this..."
      quote: ""

    - title: "Deep Painterly Harmonization"
      recommended: true
      category: "cv"
      type: "paper + github"
      lab: "Cornell University, Adobe Research"
      url: "https://arxiv.org/abs/1804.03189"
      description: "Just when I started to get used to (even bored??) by style transfer examples, this work brings a bit of fresh air. The idea is the following: you start from an existing image with a strong distinctive appearance (say a painting) and you paste on this image an element which has a completely different appearance (say a photo of a car). The goal is to modify the photo of the car so its appearance melts with the appearance of the painting, resulting in a unified painting with a car in it. The paper provides some interesting visuals but I also liked the examples provided in this <a href=https://github.com/luanfujun/deep-painterly-harmonization#examples>Github implementation</a>. Some of them are stunning. Could we use this to digitally tamper documents?"
      quote: ""

    - title: "ICLR 2018 Best Paper Award - Spherical CNNs"
      recommended: false
      category: "cv"
      type: "paper"
      lab: "University of Admsterdam, EPFL, CIFAR"
      url: "https://arxiv.org/abs/1801.10130"
      description: "CNNs designed to work with spherical images (I didn't know that existed...) such as omnidirectional vision for drones and autonomous cars, climate modelling etc. Side-note: the paper <a href=https://openreview.net/forum?id=ryQu7f-RZ>On the Convergence of Adam and Beyond</a> reviewed by @Blanca during a paper reading session also received a Best Paper Award."
      quote: ""

    - title: "Capsules for Object Segmentation"
      recommended: false
      category: "cv"
      type: "paper"
      lab: "University of Central Florida"
      url: "https://arxiv.org/abs/1804.04241"
      description: ""
      quote: "The proposed convolutional-deconvolutional capsule network, called SegCaps, shows strong results for the task of object segmentation with substantial decrease in parameter space. As an example application, we applied the proposed SegCaps to segment pathological lungs from low dose CT scans and compared its accuracy and efficiency with other U-Net-based architectures. SegCaps is able to handle large image sizes (512 x 512) as opposed to baseline capsules (typically less than 32 x 32)."

    - title: "Unsupervised Discovery of Object Landmarks as Structural Representations (CVPR 2018)"
      recommended: false
      category: "cv"
      type: "paper"
      lab: "University of Michigan, Ann Arbor, Google Brain"
      url: "https://arxiv.org/abs/1804.04412"
      description: ""
      quote: "We propose an autoencoding formulation to discover landmarks as explicit structural representations. The encoding module outputs landmark coordinates, whose validity is ensured by constraints that reflect the necessary properties for landmarks. The decoding module takes the landmarks as a part of the learnable input representations in an end-to-end differentiable framework. Our discovered landmarks are semantically meaningful and more predictive of manually annotated landmarks than those discovered by previous methods."


    - title: "Who Let The Dogs Out? Modeling Dog Behavior From Visual Data (CVPR 2018)"
      recommended: false
      category: "cv"
      type: "paper"
      lab: "University of Washington, Allen Institute for AI"
      url: "https://arxiv.org/abs/1803.10827"
      description: "See this <a href=https://techcrunch.com/2018/04/11/whos-a-good-ai-dog-based-data-creates-a-canine-machine-learning-system/>TechCrunch article</a> for an overview."
      quote: "Our model takes visual information as input and directly predicts the actions of the agent. Toward this end we introduce DECADE, a large-scale dataset of ego-centric videos from a dog's perspective as well as her corresponding movements. Using this data we model how the dog acts and how the dog plans her movements. "

    - title: "Altair"
      recommended: false
      category: "vis"
      type: "github"
      lab: ""
      url: "https://altair-viz.github.io/"
      description: "This declarative plotting library (a la ggplot from R) has just been updated to version 2.0.0. According to the changelog, this update involved a complete rewrite of the library to focus on supporting Vega-Lite 2.X which is a 'is a high-level grammar of interactive graphics'. For the love of plots."
      quote: ""

    - title: "Making the best of Jupyter"
      recommended: false
      category: "ds"
      type: "blog"
      lab: ""
      url: "https://github.com/NirantK/best-of-jupyter"
      description: "A collection of tips to improve productivity with Jupyter notebooks (how to debug, how to execute shell commands from the notebook and other tips)."
      quote: ""
