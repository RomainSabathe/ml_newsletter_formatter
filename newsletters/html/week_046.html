<!DOCTYPE html>
<html>
<title>ML newsletter</title>
<meta charset="UTF-8">

<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<!-- Optional theme -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">

<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<link rel='stylesheet' href='https://fonts.googleapis.com/css?family=Roboto'>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<style>
	html,body,h1,h2,h3,h4,h5,h6 {font-family: "Roboto", sans-serif}

	.category{
	  padding: 20px;
	  margin: auto;
	  background: #F5F5F5;
	  margin-bottom: 25px;
	  box-shadow: 0 3px 6px rgba(0,0,0,0.16), 0 3px 6px rgba(0,0,0,0.23);
	  transition: all 0.3s; 
	  border-radius: 3px;
	}

    .category-title{
      margin-bottom: 30px;
    }

	.category-logo{
	  margin-right: 10px;
	}

	.article-logo{
	  margin-right: 3px;
	}

    .recommended{
	  margin-right: 2px;
    }

    .quote{
      font-size: 11px;
    }
</style>


<body>

<!-- Page Container -->
<div class="container" style="max-width:1400px;">

  
  <!-- The Grid -->
  <div class="row">
  
      <!-- Dummy container to force centering. Yes. I'm a front-end noob. -->
      <div class="col-sm-2"></div>

      <div class="col-sm-8">

          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/653/653500.png"
                       class="fa fa-fw category-logo">General Machine Learning
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://openreview.net/group?id=ICLR.cc/2019/Conference#accepted-poster-papers">ICLR 2019 - Accepted papers</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                        <span class="badge">
                                  Recommended
                              </span>
                                                    ICLR
                  </h6>
                                    <p>A list of all the posters and orals accepted at ICLR 2019. It's just been announced this morning.</p>
              </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://tryolabs.com/blog/2018/12/19/major-advancements-deep-learning-2018/"">The major advancements in Deep Learning in 2018</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Javier Couto (Tryolabs)
                  </h6>
                                    <p>The end of the year is close! As expected, a few summaries of the year 2018 are being posted. I really enjoyed this one which focuses on the most remarkable papers published this year (according to the author's point of view!). He did a great job at introducing the problem that each paper is trying to solve and why the proposed solution could be a game-changer. The focus is on NLP (with BERT, Deep Contextualized Word Representations, transfer learning with ULMFiT) and computer vision (video-to-video synthesis and study of transfer learning in computer vision tasks). The final section also gives some well-deserved honourable mentions.</p>
              </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/25/25231.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://github.com/facebookresearch/nevergrad">Nevergrad</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Facebook
                  </h6>
                                    <p>This python package from Facebook has just been released today. It includes a set of tools to perform optimisation on non-derivable objective functions via optimisers such as particle swarm optimisation, differential evolution and others. Interestingly, this package is more than just a library of optimisers. There are actually some sub-packages to gather the experiments, plot the results or pre-process the experiment (to correctly specify to types of variables to optimise). There's even a module to optimise non-python code!</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/149/149243.png"
                       class="fa fa-fw category-logo">Deep Learning
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/174/174858.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://medium.com/waymo/learning-to-drive-beyond-pure-imitation-465499f8bcb2">Learning to Drive: Beyond Pure Imitation</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Waymo
                  </h6>
                                    <p>This is an interesting article by Waymo in which authors describe how they used supervised learning to train an autonomous vehicle (see a video <a href=https://www.youtube.com/watch?v=vnco1FRdaC0&feature=youtu.be>here</a> and <a href=https://www.youtube.com/watch?v=eRFFWnabppc>here</a>). 60 days worth of driving footage were used to train <i>ChauffeurNet</i>, a recurrent neural net that had its memory model specifically engineered for the task at hand. An important point of this post is how careful augmentation was used to train the network to deal with unexpected cases (like slight deviation from the expected trajectory, or a parked vehicle on the side of the road). By slightly modifying the target trajectory and enforcing a loss that discourages collisions, authors managed to obtain an agent that was better at dealing with scenarios that never occurred in the original training footage.</p>
              </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <img src="https://image.flaticon.com/icons/png/512/25/25231.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://github.com/kumar-shridhar/Master-Thesis-BayesianCNN">Bayesian Convolutional Neural Networks</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Kumar Shridhar
                  </h6>
                                    <p>This is the Master thesis from Mr. Shridhar. It can serve as an approachable introduction to bayesian methods in deep learning as he provides interesting visuals and explanations on <i>bayes by backprop</i>. He implements the Bayesian versions of  LeNet and AlexNet and train them on MNIST, CIFAR-10 and CIFAR-100. The code is also available.</p>
              </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <img src="https://image.flaticon.com/icons/png/512/25/25231.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://github.com/kmkolasinski/deep-learning-notes/blob/master/seminars/2018-12-Improving-DL-with-tricks/Improving_deep_learning_models_with_bag_of_tricks.pdf">Improving deep learning models with bag of tricks</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Krzysztof Kolasi≈Ñski (Fornax)
                  </h6>
                                    <p>Last week we mentioned a manuscript from Amazon where authors presented a few tips and tricks on how to squeeze a few percentage points of performance from a deep model. This link is fairly similar in the concept; although these are the slides of a presentation. The slides are well annotated and come with associated plots. The author goes over some tricks regarding the learning rate (cyclical LR, SGD with warm restarts), the size of minibatches, weight decay with Adam, or even the labels (label smoothing) etc.</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/179/179121.png"
                       class="fa fa-fw category-logo">Optimisation & Learning Theory
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1812.06855">arXiv - Bayesian Optimization in AlphaGo</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    DeepMind
                  </h6>
                                    <blockquote class="blockquote">
                     <p class="quote">During the development of AlphaGo, its many hyper-parameters were tuned with Bayesian optimization multiple times. This automatic tuning process resulted in substantial improvements in playing strength. For example, prior to the match with Lee Sedol, we tuned the latest AlphaGo agent and this improved its win-rate from 50% to 66.5% in self-play games. [...] It is our hope that this brief case study will be of interest to Go fans, and also provide Bayesian optimization practitioners with some insights and inspiration.</p>
                  </blockquote>
                                    <p></p>
              </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1812.06369">arXiv - Provable limitations of deep learning</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    EPFL, MIT
                  </h6>
                                    <blockquote class="blockquote">
                     <p class="quote">[...] This paper gives a first set of results proving that deep learning algorithms fail at learning certain efficiently learnable functions. Parity functions form the running example of our results [...] The failures shown in this paper apply to training poly-size NNs on function distributions of low cross-predictability with a descent algorithm that is either run with limited memory per sample [...]. We further claim that such types of constraints are necessary to obtain failures, in that <b>exact SGD with careful non-random initialization can learn parities.</b> [...]</p>
                  </blockquote>
                                    <p></p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/56/56243.png"
                       class="fa fa-fw category-logo">Laugh Of The Week
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <b><a href="https://twitter.com/hardmaru/status/1058141909388939264">Learning to be funny</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    
                  </h6>
                                    <p></p>
              </div>
              <hr>

                          
          </div>
                </div>
      
  <!-- Dummy container to force centering. Yes. I'm a front-end noob. -->
  <div class="col-sm-2"></div>

  <!-- End Grid -->
  </div>

    
  <!-- End Page Container -->
</div>

</body>
</html>