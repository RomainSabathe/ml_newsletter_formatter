<!DOCTYPE html>
<html>
<title>ML newsletter</title>
<meta charset="UTF-8">

<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<!-- Optional theme -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">

<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<link rel='stylesheet' href='https://fonts.googleapis.com/css?family=Roboto'>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<style>
	html,body,h1,h2,h3,h4,h5,h6 {font-family: "Roboto", sans-serif}

	.category{
	  padding: 20px;
	  margin: auto;
	  background: #F5F5F5;
	  margin-bottom: 25px;
	  box-shadow: 0 3px 6px rgba(0,0,0,0.16), 0 3px 6px rgba(0,0,0,0.23);
	  transition: all 0.3s; 
	  border-radius: 3px;
	}

    .category-title{
      margin-bottom: 30px;
    }

	.category-logo{
	  margin-right: 10px;
	}

	.article-logo{
	  margin-right: 3px;
	}

    .recommended{
	  margin-right: 2px;
    }

    .quote{
      font-size: 11px;
    }
</style>


<body>

<!-- Page Container -->
<div class="container" style="max-width:1400px;">

  <!-- The Grid -->
  <div class="row">
  
      <!-- Dummy container to force centering. Yes. I'm a front-end noob. -->
      <div class="col-sm-2"></div>

      <div class="col-sm-8">

          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/653/653500.png"
                       class="fa fa-fw category-logo">General Machine Learning
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://erikbern.com/2018/10/08/the-hackers-guide-to-uncertainty-estimates.html">The hacker's guide to uncertainty estimates</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                        <span class="badge">
                                  Recommended
                              </span>
                                                    Erik Bernhardsson
                  </h6>
                  <p>It is not an article about machine learning properly speaking but rather about statistics and uncertainy estimates in particular. Readers are not expected to know a lot (or at all) about statistics as admittedly this is a <i>hacker's guide</i>. In other words, you will find quick tips to compute the uncertainty on the mean of a distribution, performing bootstraping or using the beta distribution to get the confidence interval of a Bernouilli distribution etc.; but there is not much about <i>why</i> these methods work. So this article is great to get you started and clarify some common pratical misunderstandings. For the rest, you will need to dig deeper! </p>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/179/179121.png"
                       class="fa fa-fw category-logo">Optimisation & Learning Theory
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1810.02054">Gradient Descent Provably Optimizes Over-parameterized Neural Networks</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Carnegie Mellon University, Massachusetts Institute of Technology
                  </h6>
                  <p></p>
                                    <blockquote class="blockquote">
                     <p class="quote">[...] For an m hidden node shallow neural network with ReLU activation and n training data, we show as long as m is large enough and the data is non-degenerate, randomly initialized gradient descent converges a globally optimal solution with a linear convergence rate for the quadratic loss function. </p>
                  </blockquote>
                                </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1810.00393">Deep, Skinny Neural Networks are not Universal Approximators</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Jesse Johnson, Sanofi
                  </h6>
                  <p></p>
                                    <blockquote class="blockquote">
                     <p class="quote">[...]  In this paper, we examine the topological constraints that the architecture of a neural network imposes on the level sets of all the functions that it is able to approximate. This approach is novel for both the nature of the limitations and the fact that they are independent of network depth for a broad family of activation functions.</p>
                  </blockquote>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/112/112272.png"
                       class="fa fa-fw category-logo">Gans & Adversarial Attacks
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/25/25231.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://github.com/jonasz/progressive_infogan/">Progressive InfoGAN</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                        <span class="badge">
                                  Recommended
                              </span>
                                                    Jonasz Pamuła
                  </h6>
                  <p>You probably know about InfoGAN, a method presented at NIPS 2016 which gives a bit more  predictability to the traditional GANs via the use of <i>latent codes</i>. Simply speaking, the latent code is part of the noise vector that is used to generate an image; its particularity being that it is optimised during training to maximise its mutual information with the generated image. In other words, there's high chance that each dimension of the latent code encodes a specific property of the image (like glasses/no glasses, length of the nose etc.). Now you also likely know about Progressive Growing of GANs presented last year by NVIDIA; a method that can be used to generate HD images with astonishing levels of details. For his Master's thesis, Mr. Pamuła had the idea to combine both, and the results are fascinating!</p>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/249/249156.png"
                       class="fa fa-fw category-logo">Reinforcement Learning
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://bair.berkeley.edu/blog/2018/10/09/sfv/">Learning Acrobatics by Watching Youtube</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Berkeley Artifical Intelligence Research
                  </h6>
                  <p>As often with BAIR, this article is an introduction to their recent paper, <a href=https://xbpeng.github.io/projects/SFV/2018_TOG_SFV.pdf>SFV: Reinforcement Learning of Physical Skills from Videos</a>. Learning motion and acroabtics in particular is a hard problem. Previous methods leverage for instance imitation learning using motion capture data which is costly and long to obtain. This paper adresses this problem by learning directly from Youtube videos which is more difficult as it implies learning from raw pixel data. The main idea is actually to <i>simulate</i> having motion capture data by first estimating the pose of the human in the video and then reconstructing the motion (to counter camera shaking etc). The last step consists in standard motion-imitation RL based on the obtained pose. </p>
                                </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://designrl.github.io/">Reinforcement Learning for Improving Agent Design</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    David Ha (Google Brain)
                  </h6>
                  <p>In traditional reinforcement learning benchmarks, an agent with fixed characterics has to perform a set of actions successfully. This paper gets rid of the 'fixed characterics' constraints and instead the agent is free to <i>evolve</i>. The author claims that this kind of method has the potential to uncover novel and well-adapted designs. The page shows a bunch of videos so have a look. For instance, in the RoboschoolAnt-v1 task (where a four-legged robot needs to travel as far as possible from the origin), the agent learnt to develop long and thinner legs!</p>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/484/484582.png"
                       class="fa fa-fw category-logo">Natural Language Processing
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://davidbarber.github.io/blog/2018/09/12/Generative-Neural-Machine-Translation/">Generative Neural Machine Translation</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Harshil Shah, David Barber
                  </h6>
                  <p>That is a really interesting blog post (and paper) that is well-written enough that even if you have no prior knowledge of NLP you would be able to read along (some fundamentals on variational inference may be required). In a typical latent representation model, a vector is sampled from a prior distribution and a learned model (like a neural network) transforms this vector into an entity of interest like an image or a sentence. Here the idea of the paper is to build a representation model where the latent space is common to two (or more) languages. The latent vector <i>z</i> then models the commonality between two sentences which have the same semantic meaning but expressed in different languages. Oh and you get to know about the banana trick, which is fun (spoiler: it's pretty much the same as the EM algorithm).</p>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/263/263051.png"
                       class="fa fa-fw category-logo">Everything Else
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/25/25231.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://github.com/BayesWatch/cinic-10">CINIC-10</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Institute for Adaptive and Neural Computation - University of Edinburgh
                  </h6>
                  <p>CINIC-10 is a new dataset that has the ambition to replace CIFAR-10. Authors claim that CIFAR-10 has become too easy and the benchmarks are not necessarily representative anymore (see also <a href=https://arxiv.org/abs/1806.00451>this manuscript</a> that we relayed in June). CINIC-10 has the same classes as CIFAR-10 and the images have the same size. Actually, CIFAR-10 is included in CINIC-10. The major difference is that CINIC-10 is 4.5 times larger than CIFAR.</p>
                                </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/25/25231.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://github.com/Syllo/nvtop">NVTOP</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Maxime Schmitt
                  </h6>
                  <p>You love htop? (I do!) Then you'll love <i>nvtop</i>, the equivalent of htop for our GPUs.</p>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/56/56243.png"
                       class="fa fa-fw category-logo">Laugh Of The Week
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <b><a href="http://smbc-comics.com/comic/rise-of-the-machines">When your training set is unbalanced</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    
                  </h6>
                  <p></p>
                                </div>
              <hr>

                          
          </div>
                </div>
      
  <!-- Dummy container to force centering. Yes. I'm a front-end noob. -->
  <div class="col-sm-2"></div>

  <!-- End Grid -->
  </div>
  
  <!-- End Page Container -->
</div>

</body>
</html>