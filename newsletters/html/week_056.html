<!DOCTYPE html>
<html>
<title>ML newsletter</title>
<meta charset="UTF-8">

<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<!-- Optional theme -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">

<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<link rel='stylesheet' href='https://fonts.googleapis.com/css?family=Roboto'>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<style>
	html,body,h1,h2,h3,h4,h5,h6 {font-family: "Roboto", sans-serif}

	.category{
	  padding: 20px;
	  margin: auto;
	  background: #F5F5F5;
	  margin-bottom: 25px;
	  box-shadow: 0 3px 6px rgba(0,0,0,0.16), 0 3px 6px rgba(0,0,0,0.23);
	  transition: all 0.3s; 
	  border-radius: 3px;
	}

    .category-title{
      margin-bottom: 30px;
    }

	.category-logo{
	  margin-right: 10px;
	}

	.article-logo{
	  margin-right: 3px;
	}

    .recommended{
	  margin-right: 2px;
    }

    .quote{
      font-size: 11px;
    }
</style>


<body>

<!-- Page Container -->
<div class="container" style="max-width:1400px;">

  
  <!-- The Grid -->
  <div class="row">
  
      <!-- Dummy container to force centering. Yes. I'm a front-end noob. -->
      <div class="col-sm-2"></div>

      <div class="col-sm-8">

          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/149/149243.png"
                       class="fa fa-fw category-logo">Deep Learning
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://karpathy.github.io/2019/04/25/recipe/">A Recipe for Training Neural Networks</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                        <span class="badge">
                                  Recommended
                              </span>
                                                    Andrej Karpathy
                  </h6>
                                    <p>Andrej Karpathy hasn't written a blog post in about a year and a half, making this one all the more appreciated! This post could be yet another 'best-pratices when tuning a neural network' post and it actually is. However I don't think I have encountered such long and thorough list to 'tips and tricks' before. I'm sure some of them could be transformed into motivational images. Heck, I've made <a href=https://imgur.com/j2SBOXk>one</a>. :-) </p>
              </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://openai.com/blog/sparse-transformer/">Generative Modeling with Sparse Transformers</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    OpenAI
                  </h6>
                                    <p>OpenAI just published an improvement over the famous Transformer network. This one is called the Sparse Transformer because each output attends to only a subset of the inputs (instead of the whole range of inputs for the Transformer). This allows the model to use less memory and to be extended to larger sequences. More importantly, this architecture can work on different modalities (image, audio, text) which was not possible before (see <a href=https://arxiv.org/abs/1706.03762>Transformer</a> for text and <a href=https://arxiv.org/abs/1802.05751>Image Transformer</a> for images for instance). The post also presents nice-looking gifs that show how each layer of the Sparse Transformer can learn different patterns of attention. Official implementation is available.</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/722/722174.png"
                       class="fa fa-fw category-logo">Computer Vision
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://github.com/hzwer/LearningToPaint">LearningToPaint</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Peking University, Face++
                  </h6>
                                    <p>The official Pytorch implementation of the <a href=https://arxiv.org/abs/1903.04411>Learning to Paint with Model-based Deep Reinforcement Learning</a> paper.</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/112/112272.png"
                       class="fa fa-fw category-logo">Gans & Adversarial Attacks
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="http://krsingh.cs.ucdavis.edu/krishna_files/papers/finegan/index.html">[CVPR 2019] FineGAN: Unsupervised Hierarchical Disentanglement for Fine-Grained Object Generation and Discovery</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    University of California, Davis
                  </h6>
                                    <blockquote class="blockquote">
                     <p class="quote">We propose FineGAN, a novel unsupervised GAN framework, which disentangles the background, object shape, and object appearance to hierarchically generate images of fine-grained object categories. To disentangle the factors without any supervision, our key idea is to use information theory to associate each factor to a latent code, and to condition the relationships between the codes in a specific way to induce the desired hierarchy. Through extensive experiments, we show that FineGAN achieves the desired disentanglement to generate realistic and diverse images belonging to fine-grained classes of birds, dogs, and cars. Using FineGAN's automatically learned features, we also cluster real images as a first attempt at solving the novel problem of unsupervised fine-grained object category discovery.</p>
                  </blockquote>
                                    <p></p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/680/680208.png"
                       class="fa fa-fw category-logo">Data Science & Visualisations
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://medium.com/ai-ml-at-symantec/ai-ml-security-pro-tips-class-imbalance-and-missing-labels-764fd18b7bf8">Pro Tips: Class Imbalance and Missing Labels</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Sarfaraz Hussein
                  </h6>
                                    <p>This is an interesting post with some good examples if you have never worked on class imbalance problems or with missing labels before. The first part of the post deals with class imbalance. The author reviews several methods to tackle this problem including feature-level approaches (ADASYN, SMOTE), data-level approaches (i.e. augmentation) and algorithm-level approaches (cost-sensitive SVM, U-Net, Focal Loss,...). It's a relatively quick read as all the said methods are extremely briefly explained (2 lines or less). The second part of the post is dedicated to the problem of missing labels.</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://imageog.flaticon.com/icons/png/512/248/248114.png"
                       class="fa fa-fw category-logo">Production & Engineering
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1904.10631">[arXiv] Low-Memory Neural Network Training: A Technical Report</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Stanford University
                  </h6>
                                    <blockquote class="blockquote">
                     <p class="quote">Memory is increasingly often the bottleneck when training neural network models. Despite this, techniques to lower the overall memory requirements of training have been less widely studied compared to the extensive literature on reducing the memory requirements of inference. In this paper we study a fundamental question: How much memory is actually needed to train a neural network? To answer this question, we profile the overall memory usage of training on two representative deep learning benchmarks -- the WideResNet model for image classification and the DynamicConv Transformer model for machine translation -- and comprehensively evaluate four standard techniques for reducing the training memory requirements [...]. Using appropriate combinations of these techniques, we show that it is possible to the reduce the memory required to train a WideResNet-28-2 on CIFAR-10 by up to 60.7x with a 0.4% loss in accuracy, and reduce the memory required to train a DynamicConv model on IWSLT'14 German to English translation by up to 8.7x with a BLEU score drop of 0.15.</p>
                  </blockquote>
                                    <p></p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/56/56243.png"
                       class="fa fa-fw category-logo">Laugh Of The Week
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/8/8800.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://twitter.com/GaneshNatesh/status/1121408777964728321">OpenAI's bot against the human swarm</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Natesh Ganesh
                  </h6>
                                    <p>For context: last weekend, it was possible for anyone to play a game against OpenAI's Dota 2 bot which defeated pro gamers a few weeks ago. The bot played against nearly <a href=https://twitter.com/OpenAI/status/1120421259274334209>31,000 players</a> and lost only 0.6% of its games.</p>
              </div>
              <hr>

                          
          </div>
                </div>
      
  <!-- Dummy container to force centering. Yes. I'm a front-end noob. -->
  <div class="col-sm-2"></div>

  <!-- End Grid -->
  </div>

    
  <!-- End Page Container -->
</div>

</body>
</html>