<!DOCTYPE html>
<html>
<title>ML newsletter</title>
<meta charset="UTF-8">

<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<!-- Optional theme -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">

<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<link rel='stylesheet' href='https://fonts.googleapis.com/css?family=Roboto'>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<style>
	html,body,h1,h2,h3,h4,h5,h6 {font-family: "Roboto", sans-serif}

	.category{
	  padding: 20px;
	  margin: auto;
	  background: #F5F5F5;
	  margin-bottom: 25px;
	  box-shadow: 0 3px 6px rgba(0,0,0,0.16), 0 3px 6px rgba(0,0,0,0.23);
	  transition: all 0.3s; 
	  border-radius: 3px;
	}

    .category-title{
      margin-bottom: 30px;
    }

	.category-logo{
	  margin-right: 10px;
	}

	.article-logo{
	  margin-right: 3px;
	}

    .recommended{
	  margin-right: 2px;
    }

    .quote{
      font-size: 11px;
    }
</style>


<body>

<!-- Page Container -->
<div class="container" style="max-width:1400px;">

  
  <!-- The Grid -->
  <div class="row">
  
      <!-- Dummy container to force centering. Yes. I'm a front-end noob. -->
      <div class="col-sm-2"></div>

      <div class="col-sm-8">

          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/653/653500.png"
                       class="fa fa-fw category-logo">General Machine Learning
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://developers.google.com/machine-learning/rules-of-ml/">Best Practices for ML Engineering</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                        <span class="badge">
                                  Recommended
                              </span>
                                                    Google
                  </h6>
                                    <p>Didn't properly read it all... But it's just because I want to properly dig into that!! I feel like this page is a mine of tips and advises to keep in mind when designing a machine learning <i>product</i> from A to Z. In particular, I was suprised by the very first rule: Google, which consider itself as a 'AI first' company, recommends not to be afraid to launch a product without machine learning. Plenty of other of these recommendations suggest that good engineering is at least as important as being a good ML practioner.</p>
              </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://blog.openai.com/ai-and-compute/">AI and Compute</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    OpenAI
                  </h6>
                                    <p>A study on the number of operations that were required to train the most famous models of the deep learning era (AlexNet, VGG, LeNet, AlphaZero etc.). It is shown that this number of operations doubles every 3.5 months! In comparison, the Moore's Law estimates that processor's computing power doubles every 18 months. This study was a lot debated and shared last week.</p>
              </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://icml.cc/Conferences/2018/AcceptedPapersInitial">ICML 2018 Accepted Papers</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    
                  </h6>
                                    <p></p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/722/722174.png"
                       class="fa fa-fw category-logo">Computer Vision
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/149/149125.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://www.youtube.com/watch?v=qc5P2bvfl44">Deep Video Portraits</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    H. Kim et al.
                  </h6>
                                    <p>We have all seen these videos where by filming myself open my mouth, I could make a celebrity (like Barack Obama) opens his mouth in exactly the same way. Well this work is related to this task. One could even say it does the same thing. Although I have to say here I was stunned! The video results are astonishing. It's only once the video is scaled up that we can start detecting artifacts... Worth giving it a watch..</p>
              </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <img src="https://image.flaticon.com/icons/png/512/149/149125.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://www.youtube.com/watch?v=cnquEovq1I4">Gaussian Material Synthesis</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    TU Wien
                  </h6>
                                    <p>This work has received quite a bit of attention, both because it is interesting, but also because its first author is Károly Zsolnai-Fehér, the man behind the series of videos 'Two minute papers'. The idea is to use a neural network to perform material synthesis. The network can learn from the user's preferences, suggest new materials and importantly generate an image in a few miliseconds (compared to 40-60 seconds with traditional methods).</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/179/179121.png"
                       class="fa fa-fw category-logo">Optimisation & Learning Theory
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1805.08095">Small steps and giant leaps: Minimal Newton solvers for Deep Learning</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    University of Oxford
                  </h6>
                                    <blockquote class="blockquote">
                     <p class="quote">Our method addresses long-standing issues with current second-order solvers, which invert an approximate Hessian matrix every iteration exactly or by conjugate-gradient methods, a procedure that is both costly and sensitive to noise. Instead, we propose to keep a single estimate of the gradient projected by the inverse Hessian matrix, and update it once per iteration. [...] We then train several large models on CIFAR and ImageNet, including ResNet and VGG-f networks, where we demonstrate faster convergence with no hyperparameter tuning. Code is available.</p>
                  </blockquote>
                                    <p>When Vedaldi is listed as one of the authors, it makes you want to look at this paper more carefully. Really interested in testing this algorithm and implementing it.</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/112/112272.png"
                       class="fa fa-fw category-logo">Gans & Adversarial Attacks
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1805.08318">Self-Attention Generative Adversarial Networks</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Rutgers University, Google Brain
                  </h6>
                                    <p>It's still a preprint, but the idea is interesting and the authors (which includes Ian Goodfellow) mention what looks like to be considerable improvement when generating images based on ImageNet. It seems two main ideas are at work: one is to sample the latent space multiple times and potentially at different regions; the second is to provide the discriminator with attention capabilities: it will be able to check the consistency of a generated sample by comparing distant portions of the image.</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/45/45669.png"
                       class="fa fa-fw category-logo">Interpratibility & Fairness
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="http://bair.berkeley.edu/blog/2018/05/17/delayed-impact/">Delayed Impact of Fair Machine Learning</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                        <span class="badge">
                                  Recommended
                              </span>
                                                    Berkely AI Research
                  </h6>
                                    <p>This post makes use of a simple credit scoring scenario and a few visualisations to make us understand the difficulty (and even danger!) of choosing a fairness criterion. We are invited to take the role of a bank which can apply two different thresholds on the credit score for two different populations (one of them being a 'minority'). We see how intuitive fairness goals such as <i>demographic parity</i> or <i>equal opportunity</i> can actually be detrimental to the long-term well-being of the minority population! This work prones to have a broader view of 'fairness'; one which optimises the future of a population.</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/249/249156.png"
                       class="fa fa-fw category-logo">Reinforcement Learning
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://deepmind.com/blog/grid-cells/">Navigating with grid-like representations in artificial agents</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    DeepMind
                  </h6>
                                    <p>A short presentation of the newest Nature paper from DeepMind. I thought this work was interesting particularly because it shows such strong connection between artificial models and biological models of the brain. In the brain, grid-organised type of cells were shown to be associated with spacial localisation. By using RNNs for the task of self-localisation of a reinforcement learning agent, DeepMind researchers showed that grid-like patterns were naturally emerging in the artificial network. They monitored the activity to these units and observed indeed strong correlation with the localisation of the agent. Also, the agent was performing better at the task of navigation. This also opens up the possibility of using artificial networks to experiment and predict the behaviour or biological models. As said in the post, this has the potential to complement works already conducted on amimals.</p>
              </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/149/149125.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://www.youtube.com/watch?v=zNXgT2csQ7A">3D Printed Robot Cat learns to walk with Machine Learning</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    University of Stavanger
                  </h6>
                                    <p>In less than 2 hours, a small quadruped learns to walk efficiently by only using genetic algorithms. And it's not in a simulation! Another example that GA is competitive compared to standard gradient descent methods for reinforcement learning tasks.</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/484/484582.png"
                       class="fa fa-fw category-logo">Natural Language Processing
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1805.04833v1">Hierarchical Neural Story Generation</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Facebook AI Research
                  </h6>
                                    <p>If you have two minutes, go and check the last page of the paper. The goal is to generate stories; something that has been explored many times in the past (sometimes reaching <a href=https://www.theverge.com/2016/1/21/10805398/friends-neural-network-scripts>headlines</a>). Here I was very impressed by the overall quality of the generated text. It still feels like empty somehow, but it also seems coherent throughout the entire paragraph. This is the whole selling point of the paper: by using a hierarchical generation procedure, authors were able to generate texts that had a strong narrative baseline.</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/263/263051.png"
                       class="fa fa-fw category-logo">Everything Else
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <b><a href="https://ai.googleblog.com/2018/05/automatic-photography-with-google-clips.html">Automatic Photography with Google Clips</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Google AI Blog
                  </h6>
                                    <p>Remember! 17 weeks ago (!) in this very same newsletter we were telling you about <a href=https://design.google/library/ux-ai/>The UX of AI</a>. A blog post that showed Google's interest in trying to identify <i>worthy moments</i> in your videos. Your kids are in the parc, one of them does a backflip. That's what you want the algorithm to curate for you! At the time we didn't have much information regarding the training procedure. Now this article brings us a lot more information. What I thought was the most stunning is the HUGE amount of human labelling involved. Instead of giving a score to video samples (say 5 is 'super worthy' and 0 is 'not worthy at all'), researchers decided it would be wiser to give labellers two video samples. All the labellers had to do was to say which of the two videos is the worthier. And they obtained 50,000,000 of these comparisons. Yes. <b>50 MILLION manually labelled pairs of video samples</b>. Another interesting bit is how they tackled the problem of fairness. You can tell they cared a lot about this. For now what they did was to insure the training data was as diverse as it can and similarly the testing data featured variations of sensible features (skin color, age, etc.) under static global conditions (background, action etc.).</p>
              </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/149/149125.png"
                           class="fa fa-fw article-logo">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://www.youtube.com/watch?v=vdxCqNWTpUs">A Universal Music Translation Network</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Facebook AI Research
                  </h6>
                                    <p>I am very impressed by what they achieved. They transfer (to some extent) musics from one genre to the other. Unlike similar works that limited only to MIDI data (which doesn't sound great let's be honest), here the waveforms (or frequencies?) are generated directly. This introduces problems of artifacts that we can clearly hear, but overall the pace and dynamic of a piece are well transfered into another genre.</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/56/56243.png"
                       class="fa fa-fw category-logo">Laugh Of The Week
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <b><a href="https://twitter.com/ajmooch/status/998207618349977600">Where are internet cats gone?</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    
                  </h6>
                                    <p></p>
              </div>
              <hr>

                          
          </div>
                </div>
      
  <!-- Dummy container to force centering. Yes. I'm a front-end noob. -->
  <div class="col-sm-2"></div>

  <!-- End Grid -->
  </div>

    
  <!-- End Page Container -->
</div>

</body>
</html>