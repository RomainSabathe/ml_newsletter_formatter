<!DOCTYPE html>
<html>
<title>ML newsletter</title>
<meta charset="UTF-8">

<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<!-- Optional theme -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">

<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<link rel='stylesheet' href='https://fonts.googleapis.com/css?family=Roboto'>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<style>
	html,body,h1,h2,h3,h4,h5,h6 {font-family: "Roboto", sans-serif}

	.category{
	  padding: 20px;
	  margin: auto;
	  background: #F5F5F5;
	  margin-bottom: 25px;
	  box-shadow: 0 3px 6px rgba(0,0,0,0.16), 0 3px 6px rgba(0,0,0,0.23);
	  transition: all 0.3s; 
	  border-radius: 3px;
	}

    .category-title{
      margin-bottom: 30px;
    }

	.category-logo{
	  margin-right: 10px;
	}

	.article-logo{
	  margin-right: 3px;
	}

    .recommended{
	  margin-right: 2px;
    }

    .quote{
      font-size: 11px;
    }
</style>


<body>

<!-- Page Container -->
<div class="container" style="max-width:1400px;">

    <div class="row" style="margin-bottom:30px; margin-top:30px;">
      <div class="col-sm-2"></div>
      <div class="col-sm-8">
          <p class="text-sm-left">A lot of engineering-related projects this week, all of which are super interesting. Fast computation of euclidean distance in large databases, privacy-preserving trainings and explicit tensor reshaping and annotations,.. yummy! Have a nice Friday!</p>
      </div>
      <div class="col-sm-2"></div>
  </div>
  
  <!-- The Grid -->
  <div class="row">
  
      <!-- Dummy container to force centering. Yes. I'm a front-end noob. -->
      <div class="col-sm-2"></div>

      <div class="col-sm-8">

          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/653/653500.png"
                       class="fa fa-fw category-logo">General Machine Learning
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/25/25231.png"
                           class="fa fa-fw article-logo">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://github.com/OpenMined/PySyft">PySyft</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Imperial College London, DeepMind, Case Western Reserve University
                  </h6>
                  <p>This library allows you to do Multi-Party computation which is a sub-branch of cryptography for privacy-preserving computation, using pytorch. With PySyft, it becomes easy to create a pool of workers and distribute the data (and training) among the workers. Authors provide a docker image for ease of use as well as some examples, including one for <a href=https://colab.research.google.com/drive/1F3ALlA3ogfeeVXuwQwVoX4PimzTDJhPy#scrollTo=PTCvX6H9JDCt>federated learning</a>. The example is short and easy to understand: you create the workers, you split the dataset such that each worker will see only one part of the dataset. At training time, each worker works on its part of the data, and the model is trained based on the gradients sent back by the workers. Authors also published a <a href=https://arxiv.org/abs/1811.04017>paper</a> for this work.</p>
                                </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <b><a href="https://twitter.com/iclr2019/status/1065079004611452928">Controversial ICLR Paper submissions</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    ICLR
                  </h6>
                  <p>Interesting initiative from ICLR oganizers: they are making a list of some papers that have been particularly debated. The number of comments for each submission is quite high and I'm sure are full of interesting discussions.</p>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/149/149243.png"
                       class="fa fa-fw category-logo">Deep Learning
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/25/25231.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://github.com/reiinakano/arbitrary-image-stylization-tfjs">Arbitrary image stylization in TensorFlow.js</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Reiichiro Nakano
                  </h6>
                  <p>An open-source Tensorflow.js implementation of style transfer. A webdemo is available so you can have fun with it. There is no central server where the images are sent and processed since it uses Tensorflow.js! It's all in your browser. If you have a powerful machine, it should be quick to try lots of different content/style images combinations.</p>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/179/179121.png"
                       class="fa fa-fw category-logo">Optimisation & Learning Theory
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1803.10123">Bayesian Gradient Descent: Online Variational Bayes Learning with Increased Robustness to Catastrophic Forgetting and Weight Pruning</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Israel Institute of Technology
                  </h6>
                  <p></p>
                                    <blockquote class="blockquote">
                     <p class="quote">We suggest a novel approach for the estimation of the posterior distribution of the weights of a neural network, using an online version of the variational Bayes method. Having a confidence measure of the weights allows to combat several shortcomings of neural networks, such as their parameter redundancy, and their notorious vulnerability to the change of input distribution ('catastrophic forgetting'). Specifically, We show that this approach helps alleviate the catastrophic forgetting phenomenon - even without the knowledge of when the tasks are been switched. Furthermore, it improves the robustness of the network to weight pruning - even without re-training.</p>
                  </blockquote>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/112/112272.png"
                       class="fa fa-fw category-logo">Gans & Adversarial Attacks
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/25/25231.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb">BigGAN demo in colab notebook</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    TensorflowHub
                  </h6>
                  <p>You probably have heard of <a href=https://arxiv.org/abs/1809.11096>BigGAN</a>, a model proposed at ICLR 2019 that is capable of generating impressive real-looking images at high resolution without the need for progressive growing. This colab notebook is loaded with a pretrained BigGAN model so you can generate more of those delicious hamburger images. Or any of the thousand classes (!!) available actually. A pretrained model is always appreciated, especially when we consider that it could cost up to <a href=https://twitter.com/quasimondo/status/1065610256917692416>tens of thousands of dollars</a> to obtain it,...</p>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://imageog.flaticon.com/icons/png/512/248/248114.png"
                       class="fa fa-fw category-logo">Production & Engineering
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/174/174858.png"
                           class="fa fa-fw article-logo">
                                            <img src="https://image.flaticon.com/icons/png/512/25/25231.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://towardsdatascience.com/introducing-tensor-shape-annotation-library-tsalib-963b5b13c35b">TSALib</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Nishant Sinha
                  </h6>
                  <p>Remember having hard times trying to read the code of some complex architecture? Seeing transformations and permutations that didn't make much sense? One potential reason for this is the lack of understanding of what the code is trying to achieve and what the objects in the code are. Comments could help but it's hard to enforce them. What if we were given a tool that serves both the purpose of comments (as a documentation) <b>and</b> that could be used to perform transformations more easily (e.g: permutation, concatenation, etc.)? That is the goal of TSALib (read: Tensor Shape Annotation library). This library uses Python 3 hints mechanism to interpret the shape of tensors and provides tools to manipulate them. It supports numpy, tensorflow and pytorch. Go and check out the blog post if you want to learn more; it can serve as a sort of introduction.</p>
                                </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/25/25231.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://github.com/arogozhnikov/einops">Einops</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Alex Rogozhnikov
                  </h6>
                  <p>A library I'm quite excited about. Similarly to TSALib that we already talked about, Einops enables you to perform tensor transformations by explicitly writing the shape and dimensions of the input and expected output. For this use, it appears Einops is more powerful than TSALib (judge yourself by watching the video on the github page or checking the introductory examples <a href=https://github.com/arogozhnikov/einops/blob/master/docs/1-einops-basics.ipynb>here</a>). This is understandable since this types of transformation is the sole purpose of Einops, whereas TSALib focuses more on providing <i>annotations</i>. In other words, although Einops and TSALib have some overlaps, they are trying to achieve two different things and there are no reason why they couldn't be both used. Note that Einops supports numpy, tensorflow, pytorch, chainer, gluon, mxnet,...</p>
                                </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/25/25231.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://euclidesdb.readthedocs.io/en/latest/">EuclidesDB</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Christian S. Perone
                  </h6>
                  <p>A tool that could be extremely useful for production services that do matching and comparisons of neural network's embeddings. EuclidesDB offers C++ bindings and protobuff support for fast computation and indexing as well as gRPC for fast network communication. Examples are provided and it appears fairly easy to create a database of embeddings and to do search on them. For now it is only supported by pytorch.</p>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/56/56243.png"
                       class="fa fa-fw category-logo">Laugh Of The Week
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <b><a href="https://twitter.com/SussilloDavid/status/1065384108535119872">Ruin Thanksgiving in four words:</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    
                  </h6>
                  <p></p>
                                </div>
              <hr>

                          
          </div>
                </div>
      
  <!-- Dummy container to force centering. Yes. I'm a front-end noob. -->
  <div class="col-sm-2"></div>

  <!-- End Grid -->
  </div>

    
  <!-- End Page Container -->
</div>

</body>
</html>