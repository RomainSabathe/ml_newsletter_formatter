<!DOCTYPE html>
<html>
<title>ML newsletter</title>
<meta charset="UTF-8">

<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<!-- Optional theme -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">

<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<link rel='stylesheet' href='https://fonts.googleapis.com/css?family=Roboto'>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<style>
	html,body,h1,h2,h3,h4,h5,h6 {font-family: "Roboto", sans-serif}

	.category{
	  padding: 20px;
	  margin: auto;
	  background: #F5F5F5;
	  margin-bottom: 25px;
	  box-shadow: 0 3px 6px rgba(0,0,0,0.16), 0 3px 6px rgba(0,0,0,0.23);
	  transition: all 0.3s; 
	  border-radius: 3px;
	}

    .category-title{
      margin-bottom: 30px;
    }

	.category-logo{
	  margin-right: 10px;
	}

	.article-logo{
	  margin-right: 3px;
	}

    .recommended{
	  margin-right: 2px;
    }

    .quote{
      font-size: 11px;
    }
</style>


<body>

<!-- Page Container -->
<div class="container" style="max-width:1400px;">

  
  <!-- The Grid -->
  <div class="row">
  
      <!-- Dummy container to force centering. Yes. I'm a front-end noob. -->
      <div class="col-sm-2"></div>

      <div class="col-sm-8">

          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/149/149243.png"
                       class="fa fa-fw category-logo">Deep Learning
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1903.12436">[arXiv] From Variational to Deterministic Autoencoders</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Max Planck Institute for Intelligent Systems
                  </h6>
                                    <blockquote class="blockquote">
                     <p class="quote">Variational Autoencoders (VAEs) provide a theoretically-backed framework for deep generative models. However, they often produce 'blurry' images, which is linked to their training objective. Sampling in the most popular implementation, the Gaussian VAE, can be interpreted as simply injecting noise to the input of a deterministic decoder. In practice, this simply enforces a smooth latent space structure. We challenge the adoption of the full VAE framework on this specific point in favor of a simpler, deterministic one. Specifically, we investigate how substituting stochasticity with other explicit and implicit regularization schemes can lead to a meaningful latent space without having to force it to conform to an arbitrarily chosen prior. [...]</p>
                  </blockquote>
                                    <p></p>
              </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://staff.fnwi.uva.nl/s.abnar/?p=108">From Attention in Transformers to Dynamic Routing in Capsule Nets</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Smira Abnar (University of Amsterdam)
                  </h6>
                                    <p>The first two sections of this post are an introduction to the transformer networks and capsule networks. They can be skipped for readers who are already accustomed with those architectures. The last part however dives into the similarities and dissimilarities between the two architectures, a subject I have never encountered. <br /> In a nutshell: both of these networks have some sort of filtering mechanism by which deeper layers only receive a part of the signal coming from earlier layers. How this filtering is performed differs depending on the architecture: in transformer networks, the output of an early layer is masked several times (via the different <i>attention heads</i>) before being forwarded to the next layer (bottom up). In capsule nets, it is the units in the deeper layers that 'choose' which inputs to receive signal from using the routing mechanism (top down).</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/722/722174.png"
                       class="fa fa-fw category-logo">Computer Vision
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1903.12355v1">[arXiv] Local Aggregation for Unsupervised Learning of Visual Embeddings</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Stanford University
                  </h6>
                                    <blockquote class="blockquote">
                     <p class="quote">[...]. Here, we describe a method that trains an embedding function to maximize a metric of local aggregation, causing similar data instances to move together in the embedding space, while allowing dissimilar instances to separate. This aggregation metric is dynamic, allowing soft clusters of different scales to emerge. We evaluate our procedure on several large-scale visual recognition datasets, achieving state-of-the-art unsupervised transfer learning performance on object recognition in ImageNet, scene recognition in Places 205, and object detection in PASCAL VOC.</p>
                  </blockquote>
                                    <p></p>
              </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1904.01569">[arXiv] Exploring Randomly Wired Neural Networks for Image Recognition</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Facebook AI Research
                  </h6>
                                    <blockquote class="blockquote">
                     <p class="quote">[...] In this paper, we explore a more diverse set of connectivity patterns through the lens of randomly wired neural networks. To do this, we first define the concept of a stochastic network generator that encapsulates the entire network generation process. Encapsulation provides a unified view of [network architecture search] and randomly wired networks. Then, we use three classical random graph models to generate randomly wired graphs for networks. The results are surprising: several variants of these random generators yield network instances that have competitive accuracy on the ImageNet benchmark. These results suggest that new efforts focusing on designing better network generators may lead to new breakthroughs by exploring less constrained search spaces with more room for novel design.</p>
                  </blockquote>
                                    <p>Code is available <a href=https://github.com/seungwonpark/RandWireNN>here</a>.</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/112/112272.png"
                       class="fa fa-fw category-logo">Gans & Adversarial Attacks
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://distill.pub/2019/gan-open-problems/">[Distill] Open Questions about Generative Adversarial Networks</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Augustus Odena (Google Brain)
                  </h6>
                                    <p>This article can be seen as a short survey on the challenges faced by the GAN community. It lays out important questions such as the influence of batch size, the relationship with other generative models or the type of distribution that can be modelled by a GAN. The article differs from other Distill articles in the sense that the intent is not to teach a specific notion (using fancy graphs and animations) but rather to pinpoint areas of research.</p>
              </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/25/25231.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://github.com/facebookresearch/pytorch_GAN_zoo?fbclid=IwAR0mhvTD192Lq1nrW8ZGHvHpq2KMq7BxtxeFBAB7yjH58zA3XT3DCi1Qxsc">Gan zoo: A mix of GAN implementations</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Facebook Research
                  </h6>
                                    <p>A Facebook implementation of some state-of-art GANs with Pytorch. Currently it is featuring the <a href=https://arxiv.org/pdf/1710.10196.pdf>Progressive Growing of GANs</a> and <a href=https://arxiv.org/pdf/1511.06434.pdf>DCGAN</a>. <a href=https://arxiv.org/abs/1812.04948>StyleGAN</a> will follow shortly.</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/484/484582.png"
                       class="fa fa-fw category-logo">Natural Language Processing
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://machinetalk.org/2019/03/29/neural-machine-translation-with-attention-mechanism/">Neural Machine Translation With Attention Mechanism</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                        <span class="badge">
                                  Recommended
                              </span>
                                                    <a href=https://machinetalk.org/>Machine Talk</a>
                  </h6>
                                    <p>If you wanted to start an NLP toy project, you could read this post and get started in minutes. I found the author very didactic, providing sufficient amount of details to explain how Seq2Seq and attention models work, as well as clean and structured code. Bonus: the code uses Tensorflow 2.0 :)</p>
              </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://imageog.flaticon.com/icons/png/512/248/248114.png"
                       class="fa fa-fw category-logo">Production & Engineering
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://www.debugmind.com/2019/04/07/a-primer-on-tensorflow-2-0/">A Primer on TensorFlow 2.0</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    <a href=https://www.debugmind.com/>Debug Mind</a>
                  </h6>
                                    <p>Tensorflow 2.0 described by one of its key contributors! It is obvious when reading the post that the author, Akshay Agrawal, is passionate about software engineering, which makes it all the more entertaining to go through. He provides an overview of the key changes that are coming with the new version of Tensorflow and confirms several times that the Keras API is optional: TF stays as flexible as before. I particularly liked the honest comparisons between Tensorflow and other frameworks like Pytorch 1.0. In some cases, he even went to say that for specific use cases <i>TorchScript</i> would be better than <i>tf.function</i>.</p>
              </div>
              <hr>

                          
          </div>
                </div>
      
  <!-- Dummy container to force centering. Yes. I'm a front-end noob. -->
  <div class="col-sm-2"></div>

  <!-- End Grid -->
  </div>

    
  <!-- End Page Container -->
</div>

</body>
</html>