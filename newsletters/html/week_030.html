<!DOCTYPE html>
<html>
<title>ML newsletter</title>
<meta charset="UTF-8">

<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<!-- Optional theme -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">

<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<link rel='stylesheet' href='https://fonts.googleapis.com/css?family=Roboto'>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<style>
	html,body,h1,h2,h3,h4,h5,h6 {font-family: "Roboto", sans-serif}

	.category{
	  padding: 20px;
	  margin: auto;
	  background: #F5F5F5;
	  margin-bottom: 25px;
	  box-shadow: 0 3px 6px rgba(0,0,0,0.16), 0 3px 6px rgba(0,0,0,0.23);
	  transition: all 0.3s; 
	  border-radius: 3px;
	}

    .category-title{
      margin-bottom: 30px;
    }

	.category-logo{
	  margin-right: 10px;
	}

	.article-logo{
	  margin-right: 3px;
	}

    .recommended{
	  margin-right: 2px;
    }

    .quote{
      font-size: 11px;
    }
</style>


<body>

<!-- Page Container -->
<div class="container" style="max-width:1400px;">

  <!-- The Grid -->
  <div class="row">
  
      <!-- Dummy container to force centering. Yes. I'm a front-end noob. -->
      <div class="col-sm-2"></div>

      <div class="col-sm-8">

          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/149/149243.png"
                       class="fa fa-fw category-logo">Deep Learning
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1807.10875">TensorFuzz: Debugging Neural Networks with Coverage-Guided Fuzzing</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Google Brain
                  </h6>
                  <p>This paper deals with the many uncertainties that we face when releasing models to production. Will the predictions be consistent? Will the model crash for some inputs? We can see there are at least two types of uncertainties: the first one is concerned with overfitting and the model's generalization capabilities while the second is linked to stability of the running code (numerical errors such as NaNs could make the code crash). While the former issue of overfitting is vastly explored in the litterature, the latter is often overlooked. In this work, authors take inspiration from code <i>fuzzing</i> where an algorithm is aggresively testing all possibilities of a code to find ways to make it crash (imagine testing all if/else branch combinations for instance). They define what <i>fuzzing</i> would mean for the activations of a neural network and show in some toy experiments that their algorithm is able to find numerical errors and inconsistencies on a trained network.</p>
                                    <blockquote class="blockquote">
                     <p class="quote">In this work, we introduce automated software testing techniques for neural networks that are well-suited to discovering errors which occur only for rare inputs. Specifically, we develop coverage-guided fuzzing (CGF) methods for neural networks. [...] We then discuss the application of CGF to the following goals: finding numerical errors in trained neural networks, generating disagreements between neural networks and quantized versions of those networks, and surfacing undesirable behavior in character level language models.</p>
                  </blockquote>
                                </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="http://www.offconvex.org/2018/07/27/approximating-recurrent/">When Recurrent Models Don't Need to be Recurrent</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    John Miller - Off the convex path
                  </h6>
                  <p>Over the last year, the landscape of recurrent neural networks has started to shift, particularly after the introduction of the <a href=https://arxiv.org/abs/1706.03762>Transformer</a> and of <a href=https://arxiv.org/abs/1705.03122>convolutional sequence-to-sequence models</a>. This blog post comes as an introduction to these changes. It explains why complex feed-forward models are gaining more and more attraction for tasks usually handled by recurrent models. The post also serves as an opening for the paper published by the author: <a href=https://arxiv.org/abs/1805.10369>When Recurrent Models Don't Need to be Recurrent</a>.</p>
                                </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1807.11205">Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four Minutes</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Tencent Inc., Hong Kong Baptist University
                  </h6>
                  <p>This work has received a lot of attention in the community lately. The reason is quite simple: they obtained close-to state-of-the-art performance on ImageNet in less than 10 minutes. Less than 7 minutes even! A year ago, the fastest we could do was <a ref=https://arxiv.org/abs/1706.02677>in about an hour</a>. The paper proposes multiple innovations that made this possible. In particular, they were able to scale up the batch size and yet achieve consistent training (from a batch size of 8,192 in the previous work to 64,000 here). At the same time, the number of GPUs also scaled up... from 256 to 1,024 and even 2,048!</p>
                                    <blockquote class="blockquote">
                     <p class="quote">Our training system can achieve 75.8% top-1 test accuracy [on ImageNet] in only 6.6 minutes using 2048 Tesla P40 GPUs. When training AlexNet with 95 epochs, our system can achieve 58.7% top-1 test accuracy within 4 minutes, which also outperforms all other existing systems.</p>
                  </blockquote>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/722/722174.png"
                       class="fa fa-fw category-logo">Computer Vision
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/25/25231.png"
                           class="fa fa-fw article-logo">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://github.com/fwang91/IMDb-Face">ECCV 2018 - The Devil of Face Recognition is in the Noise</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    SenseTime Research, University of California, Nanyang Technological University
                  </h6>
                  <p>Authors explore the influence of noise in terms of labels for face recognition performance. Many of the large-scale face datasets publicly available are well-known for being quite noisy. In this work, they release a cleaned version of the MegaFace and MS-Celeb-1M dataset and share their insights.</p>
                                    <blockquote class="blockquote">
                     <p class="quote">While a variety of architectures and loss functions have been devised, we still have a limited understanding of the source and consequence of label noise inherent in existing datasets. We make the following contributions: [...] with the original datasets and cleaned subsets, we profile and analyze label noise properties of MegaFace and MS-Celeb-1M. <b>We show that a few orders more samples are needed to achieve the same accuracy yielded by a clean subset.</b> [...]</p>
                  </blockquote>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/179/179121.png"
                       class="fa fa-fw category-logo">Optimisation & Learning Theory
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1807.09289">ICML 2018 Workshop - Reliable Uncertainty Estimates in Deep Neural Networks using Noise Contrastive Priors</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    Google Brain, Deep Mind
                  </h6>
                  <p></p>
                                    <blockquote class="blockquote">
                     <p class="quote">We propose noise contrastive priors (NCPs). The key idea is to train the model to output high uncertainty for data points outside of the training distribution. NCPs do so using an input prior, which adds noise to the inputs of the current mini batch, and an output prior, which is a wide distribution given these inputs. NCPs are compatible with any model that represents predictive uncertainty, are easy to scale, and yield reliable uncertainty estimates throughout training.</p>
                  </blockquote>
                                </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://arxiv.org/abs/1805.08522">Deep learning generalizes because the parameter-function map is biased towards simple functions</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    University of Oxford
                  </h6>
                  <p></p>
                                    <blockquote class="blockquote">
                     <p class="quote">[...] By applying a modified version of the coding theorem from algorithmic information theory and by performing extensive empirical analysis of random neural networks, we argue that <b>the parameter function map of deep neural networks is exponentially biased towards functions with lower descriptional complexity</b>. We show explicitly for supervised learning of Boolean functions that the intrinsic simplicity bias of deep neural networks means that they generalize significantly better than an unbiased learning algorithm does.</p>
                  </blockquote>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/249/249156.png"
                       class="fa fa-fw category-logo">Reinforcement Learning
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <img src="https://image.flaticon.com/icons/png/512/25/25231.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://dylandjian.github.io/alphago-zero/">AlphaGo Zero demystified</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                        <span class="badge">
                                  Recommended
                              </span>
                                                    Dylan Djian
                  </h6>
                  <p>The author explains how he went to reproduce the results of AlphaGo Zero. I found his explanations very clear and he made both the code and the concepts of AlphaGo Zero easier to grasp. A fair amount of engineering went into this project (with the use of async processes, databases, etc.) which makes it all the more interesting. </p>
                                </div>
              <hr>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/60/60736.png"
                           class="fa fa-fw article-logo">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="https://blog.openai.com/learning-dexterity/">Learning Dexterity</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    OpenAI
                  </h6>
                  <p>This article explains how researchers from OpenAI managed to train a physical robotic hand to manipulate objects such as a cube. Handling a hand remains a tough problem in robotics. Here, all the training was done in a simulated environment and absolutely no data coming from real-world experimences has been used. </p>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/263/263051.png"
                       class="fa fa-fw category-logo">Everything Else
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <img src="https://image.flaticon.com/icons/png/512/155/155292.png"
                           class="fa fa-fw article-logo">
                                            <b><a href="http://innovate.ee.ucla.edu/wp-content/uploads/2018/07/2018-optical-ml-neural-network.pdf">All-Optical Machine Learning Using Diffractive Deep Neural Networks</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    University of California, California NanoSystems Institute
                  </h6>
                  <p>Researchers built a physical optical system mimicking an artificial neural network that is able to perform classification based on light sources. A quite promising concept although commentators pointed out that this setup doesn't incorporate any non-linearities... yet?</p>
                                    <blockquote class="blockquote">
                     <p class="quote">. We introduce a physical mechanism to perform machine learning by demonstrating an all-optical Diffractive Deep Neural Network (D2NN) architecture that can implement various functions following the deep learning-based design of passive diffractive layers that work collectively. [...] Our all-optical deep learning framework can perform, at the speed of light [...]</p>
                  </blockquote>
                                </div>
              <hr>

                          
          </div>
          
          <!-- Category block -->
          <div class="category">
              <h2 class="category-title">
                  <img src="https://image.flaticon.com/icons/png/512/56/56243.png"
                       class="fa fa-fw category-logo">Laugh Of The Week
              </h2>

              
              <div class="article">
                  <h5 class="article-title">
                                            <b><a href="https://twitter.com/FarzaTV/status/1024760457461002240">yo dude, wanna drink?</a></b>
                  </h5>

                  <h6 class="w3-text">
                                                    
                  </h6>
                  <p></p>
                                </div>
              <hr>

                          
          </div>
                </div>
      
  <!-- Dummy container to force centering. Yes. I'm a front-end noob. -->
  <div class="col-sm-2"></div>

  <!-- End Grid -->
  </div>
  
  <!-- End Page Container -->
</div>

</body>
</html>